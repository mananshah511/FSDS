{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55ccf549-ab13-4507-a2ed-7762826a527f",
   "metadata": {},
   "source": [
    "1. What exactly is a feature? Give an example to illustrate your point."
   ]
  },
  {
   "cell_type": "raw",
   "id": "351f3ef5-e994-4630-aa77-a4292378aba6",
   "metadata": {},
   "source": [
    "We have independent, dependent features available in our data set. The dependent feature is basically our Target variable. From the set of independent features, we select a subset of features that is significant to predict our Target variable. For example, the number of bedrooms, and location is the significance feature to predict housing prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b16ca6-bc45-416c-8362-4f29e176fb4f",
   "metadata": {},
   "source": [
    "2. What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86bd4bd8-7e99-4f98-9222-003da808ee34",
   "metadata": {},
   "source": [
    "Feature Construction is required in the following situation:\n",
    "when we need relevant data from the existing data set available.\n",
    "For example, arrival and departure time of the flight is available we can construct a new feature to find journey timing.\n",
    "In some situation combination of two feature provide a significant relation with our Target variable in that case we also try future Construction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ea10f-a0d6-4852-9bf2-e61fa880d5cf",
   "metadata": {},
   "source": [
    "3. Describe how nominal variables are encoded."
   ]
  },
  {
   "cell_type": "raw",
   "id": "356b3d93-4e79-43c6-8db1-c2db9ec64cd8",
   "metadata": {},
   "source": [
    "Nominal variables are encoded using one hot encoding technique.  We assign value zero to one or more to our nominal feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf942c0-dd5a-47a7-b90a-4528118aaa58",
   "metadata": {},
   "source": [
    "4. Describe how numeric features are converted to categorical features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "08d2b141-4b64-4b26-afd5-3c8be7641cce",
   "metadata": {},
   "source": [
    "We can use a particular set of intervals and assign them category value, generally, this method is called binning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836d480d-6620-456d-aa80-66f13dea3ef6",
   "metadata": {},
   "source": [
    "5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this\n",
    "approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc9064-42d2-4987-8d10-8dbf63d72e54",
   "metadata": {},
   "source": [
    "In a wrapper method, we select features by trying all the combinations of the feature with the selected machine learning algorithm, fitting, and evaluating. And then selecting features that are performing best. Advantages we get better performing algorithm. Disadvantages there might be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f09f71-0728-4a05-86bb-aef7974ea6e3",
   "metadata": {},
   "source": [
    "6. When is a feature considered irrelevant? What can be said to quantify it?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f42e94c-dad4-42aa-bfe8-be26a7f535f5",
   "metadata": {},
   "source": [
    "If the feature has poor data quality like it has a more null or missing value. The relation between that feature and our Target variable is not significant. The feature is not providing any significance in the total output of our Target variable. Adding these features is leading to less accuracy then we can say the feature is irrelevant and we can drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44604d25-f764-4fc0-94f6-f2a487070631",
   "metadata": {},
   "source": [
    "7. When is a function considered redundant? What criteria are used to identify features that could\n",
    "be redundant?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb27361f-c8bc-47dd-b58f-98bea7600c24",
   "metadata": {},
   "source": [
    "Let's say we have a set of features X1 and X2 if X1 and X2 are highly correlated then we can drop any one of them. By correlation and covariance, we can find and drop features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834853cd-c162-4904-af30-9149349ffecf",
   "metadata": {},
   "source": [
    "8. What are the various distance measurements used to determine feature similarity?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "162c6c72-c018-4236-a915-67e0ca520238",
   "metadata": {},
   "source": [
    "Euclidean,Manhattan,chai Square analysis,Heming distance etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9544e5-120e-4ab1-909c-6626419688b7",
   "metadata": {},
   "source": [
    "9. State difference between Euclidean and Manhattan distances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af541e-0763-454c-b825-0d7bcd83c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "Euclidean distance : d = √[ (x2 – x1)2 + (y2 – y1)2]\n",
    "\n",
    "Manhattan distance : Dmi(x,y)=|xi−yi|... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71901b-90f3-4de1-9cab-6e988b4f12f9",
   "metadata": {},
   "source": [
    "10. Distinguish between feature transformation and feature selection."
   ]
  },
  {
   "cell_type": "raw",
   "id": "17a2c1fd-b501-4011-a96e-e1154d5fa034",
   "metadata": {},
   "source": [
    "Feature transformation transports the data which helps to improve the accuracy of the model. Feature selection means selecting the best feature and dropping the irrelevant feature which also helps to improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26772e67-b60d-46b2-9957-a8e17ec73ebc",
   "metadata": {},
   "source": [
    "11. Make brief notes on any two of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75331e-b6ac-4bf3-9dd1-07fd4fa5756a",
   "metadata": {},
   "source": [
    "2. Collection of features using a hybrid approach"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03e72a85-c15c-4d1e-a1e5-708af0114d81",
   "metadata": {},
   "source": [
    "It uses different feature selection method and evulate to find best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b099f91-f172-4ab8-a0b0-28f7fde7e964",
   "metadata": {},
   "source": [
    "3. The width of the silhouette"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b624584-0ff7-49f2-9f81-7f457551c2e3",
   "metadata": {},
   "source": [
    "Silhouette is a clustering validation technique to determine how the object is related to its own cluster and how the object is separated from the neighbor cluster. Score range between -1 to + 1. A positive value indicates that the object is related to the Cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fab09-3184-49ae-816c-dcc6441dadf1",
   "metadata": {},
   "source": [
    "4. Receiver operating characteristic curve"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5ff064c-cf89-49e3-98fd-191c475894ab",
   "metadata": {},
   "source": [
    "Roc curve is a graphical method generally used in binary classification to determine how threshold values vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7d79e-27a4-4729-8c15-5ba163a78524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
